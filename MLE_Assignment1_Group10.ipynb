{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T17:18:46.674464Z",
     "start_time": "2025-11-25T17:18:46.530049Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Additional packages \n",
    "import random\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, accuracy_score, f1_score, balanced_accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.datasets import make_classification\n",
    "###############################################################################\n",
    "df = pd.read_csv('mle_assignment1_2024.csv')\n",
    "df.info()\n",
    "\n",
    "# Create Traning and Test Sets\n",
    "df_train = df[:3000]\n",
    "df_test = df[3000:]\n",
    "n_test = df_test.shape[0]\n",
    "\n",
    "df_train.info()\n",
    "df_test.info()\n",
    "\n",
    "# Create the dictionary variables to save your forecasts\n",
    "# Make sure to overwrite the arrays with the predicted labels in {-1,1}\n",
    "\n",
    "Y_pred = dict()\n",
    "Y_pred['SVM'] = np.zeros((n_test,)) # Support Vector Machine\n",
    "Y_pred['NN'] = np.zeros((n_test,))  # Shallow Neural Network\n",
    "Y_pred['AB'] = np.zeros((n_test,))  # AdaBoost\n",
    "Y_pred['AC'] = np.zeros((n_test,))  # Advanced Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Support Vector Machine\n",
    "\n",
    "Let's start with a support vector machine as our baseline. Save your forecasts on the test set in `Y_pred['SVM']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and y in train and test sets\n",
    "X_train, y_train = df_train.drop(['target'], axis=1), df_train['target']\n",
    "X_test = df_test.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2024) # Set random seed\n",
    "SVM = LinearSVC(max_iter=1000, loss='squared_hinge', dual=False, random_state=42)\n",
    "SVM.fit(X_train, y_train)\n",
    "Y_pred['SVM'] = SVM.predict(X_test); Y_pred['SVM'] # Save the predictions to the 'SVM' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid-search to find the optimal value of C and number of max iterations, and evaluate the optimized model\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# Define parameter grid for C and max_iter\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'max_iter': [6,10,20,100,500, 1000, 2000],\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "SVM = LinearSVC(loss='squared_hinge', dual=False, random_state=42)\n",
    "\n",
    "# Set up grid search \n",
    "grid_search = GridSearchCV(estimator=SVM, param_grid=param_grid, scoring=scoring, refit='accuracy', cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best parameters and scores\n",
    "best_C = grid_search.best_params_['C']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "print(f\"Best C: {best_C}\")\n",
    "print(f\"Best Number of iterations: {best_max_iter}\")\n",
    "\n",
    "# Results for each scoring metric\n",
    "print(\"\\nCross-Validation Results for the Best Model:\")\n",
    "print(f\"Best Accuracy: {grid_search.cv_results_['mean_test_accuracy'][grid_search.best_index_]:.2f}\")\n",
    "print(f\"Best Balanced Accuracy: {grid_search.cv_results_['mean_test_balanced_accuracy'][grid_search.best_index_]:.2f}\")\n",
    "print(f\"Best F1 Score: {grid_search.cv_results_['mean_test_f1'][grid_search.best_index_]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Shallow Neural Network (one-hidden-layer neural network )\n",
    "\n",
    "You can just use `Keras` to train your Network. Save your forecasts on the test set in `Y_pred['NN']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate we want to use a sequential neural network\n",
    "model = Sequential()\n",
    "\n",
    "# Add hidden layer\n",
    "model.add(Dense(units=2, activation='sigmoid')) \n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(units=1, activation='tanh'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])       \n",
    "\n",
    "# Fit\n",
    "model_fit = model.fit(X_train, y_train, epochs=1000, batch_size=400, verbose=0)       \n",
    "\n",
    "# Save the predictions using test dataset\n",
    "y_hat = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign -1 for negative predictions, 1 for positive predictions, and randomly choose -1 or 1 if the prediction is exactly 0\n",
    "Y_pred_NN = np.where(y_hat < 0, -1, np.where(y_hat > 0, 1, np.random.choice([-1, 1]))) \n",
    "\n",
    "# Make sure Y_pred_NN is a 1D array of shape (n,)\n",
    "Y_pred_NN = Y_pred_NN.flatten()\n",
    "\n",
    "# Save results to the 'NN' column\n",
    "Y_pred['NN'] = Y_pred_NN; Y_pred['NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid-search to find the optimal optimizer, activation function, batch size, and number of epochs \n",
    "# and evaluate the optimized model\n",
    "\n",
    "# Convert to NumPy arrays (no need for .values)\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "# Define function to create the Keras model\n",
    "def create_model(optimizer='rmsprop', activation='tanh'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1, activation=activation))\n",
    "    model.add(Dense(units=1, activation=activation))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model for use in scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'optimizer': ['rmsprop', 'adam'],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'batch_size': [10, 20],\n",
    "    'epochs': [100, 150]\n",
    "}\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics for grid search\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=-1, refit='accuracy')\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_result.best_params_)\n",
    "\n",
    "# Retrieve and print the best scores for accuracy, balanced accuracy, and F1\n",
    "best_index = grid_result.best_index_\n",
    "best_accuracy = grid_result.cv_results_['mean_test_accuracy'][best_index]\n",
    "best_balanced_accuracy = grid_result.cv_results_['mean_test_balanced_accuracy'][best_index]\n",
    "best_f1_score = grid_result.cv_results_['mean_test_f1'][best_index]\n",
    "\n",
    "print(\"\\nCross-Validation Results for the Best Model:\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best Balanced Accuracy: {best_balanced_accuracy:.4f}\")\n",
    "print(f\"Best F1 Score: {best_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic AdaBoost\n",
    "\n",
    "Save your forecasts on the test set in `Y_pred['AB']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing back values in the training set from 0 to -1\n",
    "y_train[y_train == 0] = -1 \n",
    "\n",
    "# Define the number of estimators to start with\n",
    "n_estimators = 500\n",
    "\n",
    "# Initialize a model\n",
    "AdaB = AdaBoostClassifier(n_estimators = n_estimators, learning_rate = 1, random_state = 42)\n",
    "\n",
    "# Fit the model to training data\n",
    "AdaB.fit(X_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred['AB']= AdaB.predict(X_test); Y_pred['AB'] # Save results to the 'AB' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid-search to find the optimal number of estimators and learning rate, and evaluate the optimized model\n",
    "\n",
    "# Define X and y\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "# Define the model\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 75, 100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.05, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics for grid search\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=cv, n_jobs=-1, refit='accuracy')\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Extract the best model\n",
    "best_model = grid_result.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_result.best_params_)\n",
    "\n",
    "# Retrieve and print the best scores for accuracy, balanced accuracy, and F1\n",
    "best_index = grid_result.best_index_\n",
    "best_accuracy = grid_result.cv_results_['mean_test_accuracy'][best_index]\n",
    "best_balanced_accuracy = grid_result.cv_results_['mean_test_balanced_accuracy'][best_index]\n",
    "best_f1_score = grid_result.cv_results_['mean_test_f1'][best_index]\n",
    "\n",
    "print(\"\\nCross-Validation Results for the Best Model:\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best Balanced Accuracy: {best_balanced_accuracy:.4f}\")\n",
    "print(f\"Best F1 Score: {best_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Classifier\n",
    "\n",
    "**Choose one** of the above basic classifiers (which seems most promising to you) and optimize as much as possible. You can think of optimizing hyper parameters/regularization using (cross-)validation.\n",
    "\n",
    "Please  make  sure  all  steps  are  well  motivated  and  presented  in  a  clear and structured way.\n",
    "\n",
    "Save your forecasts on the test set in `Y_pred['AC']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=300 # Optimized value\n",
    "\n",
    "# Initialize a model\n",
    "AdaB = AdaBoostClassifier(\n",
    "    n_estimators=n_estimators, \n",
    "    learning_rate=0.05, # Optimized value\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "AdaB.fit(X_train,y_train.ravel())\n",
    "\n",
    "Y_pred['AC'] = AdaB.predict(X_test); Y_pred['AC'] # Save results to the 'AC' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain** why you have chosen this classifier and how you improved the basic model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer: We evaluated three models — BSVM, NN, and AdaBoost — using accuracy, balanced accuracy, and F1 score as metrics, and employed cross-validation to assess their performance. Our results show that AdaBoost performed the best, with an accuracy of 0.65, balanced accuracy of 0.65, and an F1 score of 0.69. To further improve AdaBoost, we optimized its hyperparameters (number of estimators and learning rate) using grid search with cross-validation. We found that the optimized values were 300 estimators and a learning rate of 0.05. We then trained the Advanced Classifier using these optimized parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, Save Your Estimates to a CSV File\n",
    "\n",
    "Save estimates for the all $n_{test}=2000$ observations in the test set:\n",
    "- Make sure each target estimate takes only the value -1 or 1\n",
    "- You receive a zero mark on the model(s) for which your estimates contain missing value(s).\n",
    "- Of course, you can't determine the accuracy\n",
    "- Save your estimates in the dictionary `Y_pred` and save them into a csv file\n",
    "- Your mark depends on how well your estimates are compared to those of other groups.\n",
    "- Make sure to replace `group_nr' in the filename by your group number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_pd=pd.DataFrame.from_dict(Y_pred) # please save your estimates in a pandas series \n",
    "Y_pred_pd.to_csv('mle_assignment1_group10.csv',index=False) # replace `group_nr' in the filename by your group number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please upload both the completed Jupyter Notebook file and the csv file containing your estimates to Canvas (using separate links)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
